{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-27T10:20:20.069442268Z",
     "start_time": "2023-10-27T10:20:13.313542882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('/home/vacekpa2/4D-RNSFP')  \n",
    "import sys\n",
    "# sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from data.dataloader import SFDataset4D\n",
    "from pytorch3d.ops.knn import knn_points\n",
    "from vis.deprecated_vis import *\n",
    "from loss.flow import DT, SmoothnessLoss\n",
    "from data.range_image import VisibilityScene\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "dataset = SFDataset4D(dataset_type='waymo', n_frames=5, only_first=False)\n",
    "data = dataset[80]\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "pc1 = data['pc1'].to(device)\n",
    "pc2 = data['pc2'].to(device)\n",
    "pose12 = data['relative_pose'].to(device)\n",
    "\n",
    "full_pc2 = data['full_pc2'][4].to(device)\n",
    "id_mask1 = data['id_mask1'].to(device)\n",
    "\n",
    "print(len(torch.unique(id_mask1)))\n",
    "# Freespace = VisibilityScene(dataset='waymo', pc_scene=full_pc2)\n",
    "# visibility_depth = Freespace.assign_depth_to_flow(pc1[0])\n",
    "# orig_depth = pc1[0].norm(dim=1)\n",
    "# valid_mask = visibility_depth > 0\n",
    "# visualize_multiple_pcls(*[pc1[i].cpu() for i in range(0,3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Freespace Notes\n",
    "- The sensor is quite noisy even still\n",
    "- Just accumulate the static points and refer to them when building the map\n",
    "- Kabsch from map points, flow in a same way\n",
    "- Use 2D raycasting from cvpr papers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9272c506aa73791"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rigid Flow and Pred Flow Notes\n",
    "- NeuralPrior is bad if we calculate metric for MOS from Flow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61fb185686156b1a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Adjacent NN for motion segmentation\n",
    "from loss.flow import SmoothnessLoss, DT\n",
    "import torch\n",
    "from pytorch3d.ops.knn import knn_points\n",
    "\n",
    "from data.dataloader import SFDataset4D\n",
    "from pytorch3d.ops.knn import knn_points\n",
    "from vis.deprecated_vis import *\n",
    "from loss.flow import DT, SmoothnessLoss\n",
    "from data.range_image import VisibilityScene\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "dataset = SFDataset4D(dataset_type='waymo', n_frames=5, only_first=False)\n",
    "data = dataset.__getitem__(80)\n",
    "\n",
    "pc1 = data['pc1'].to(device)\n",
    "pc2 = data['pc2'].to(device)\n",
    "\n",
    "# pc = pc1[:3]\n",
    "pc = [pc1[i][pc1[i, :, 2] > 0.3] for i in range(0, 3)]\n",
    "\n",
    "# pc = pc[:, pc[:,:,2] > 0.3]\n",
    "c_pc = pc[1].unsqueeze(0)\n",
    "b_pc = pc[2].unsqueeze(0)\n",
    "f_pc = pc[0].unsqueeze(0)\n",
    "# params\n",
    "forth_flow = torch.zeros(c_pc.shape, device=device, requires_grad=True)\n",
    "back_flow = torch.zeros(c_pc.shape, device=device, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([forth_flow, back_flow], lr=0.008)\n",
    "# losses\n",
    "SM_loss = SmoothnessLoss(pc1=c_pc, K=16, max_radius=1)\n",
    "\n",
    "\n",
    "b_DT = DT(c_pc, b_pc)\n",
    "f_DT = DT(c_pc, f_pc)\n",
    "\n",
    "for i in range(500):\n",
    "    # forth_dist, forth_nn, _ = knn_points(c_pc + forth_flow, f_pc, K=1, return_nn=True)\n",
    "    # back_dist, back_nn, _ = knn_points(c_pc + back_flow, b_pc, K=1, return_nn=True)\n",
    "    forth_dist, _ = f_DT.torch_bilinear_distance(c_pc + forth_flow)\n",
    "    back_dist, _ = b_DT.torch_bilinear_distance(c_pc + back_flow)\n",
    "    \n",
    "    dist_loss = (forth_dist + back_dist).mean()\n",
    "    smooth_loss = SM_loss(c_pc, forth_flow, f_pc) + SM_loss(c_pc, back_flow, f_pc)\n",
    "    \n",
    "    time_smooth = (forth_flow - (-back_flow)).norm(dim=2, p=1).mean()   # maybe magnitude of flow?\n",
    "    \n",
    "    loss = dist_loss + smooth_loss + time_smooth\n",
    "    \n",
    "    # print(i, loss, time_smooth)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# DBSCAN?\n",
    "from sklearn.cluster import DBSCAN\n",
    "mos = (forth_flow[0].norm(dim=1, p=1) > 0.05).detach().cpu().numpy()\n",
    "numpy_c_pc = c_pc.detach().cpu().numpy()\n",
    "numpy_forth_flow = forth_flow.detach().cpu().numpy()\n",
    "\n",
    "motion_pc = np.concatenate((numpy_c_pc[0, mos], numpy_forth_flow[0, mos]), axis=1)\n",
    "\n",
    "clustering = DBSCAN(eps=0.4, min_samples=5).fit_predict(motion_pc)\n",
    "\n",
    "ids = clustering\n",
    "\n",
    "\n",
    "\n",
    "# visualize_points3D(motion_pc, clustering)\n",
    "# VISUALS\n",
    "# visualize_flow3d(c_pc[0], f_pc[0], back_flow[0])\n",
    "# visualize_flow3d(c_pc[0], f_pc[0], forth_flow[0])\n",
    "# visualize_points3D(c_pc[0], forth_flow[0].norm(dim=1, p=1) > 0.05)\n",
    "# visualize_points3D(c_pc[0], forth_flow[0].norm(dim=1, p=1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T12:12:25.157920104Z",
     "start_time": "2023-10-25T12:12:21.211494940Z"
    }
   },
   "id": "11d8999cd9a704c0"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# DBSCAN?\n",
    "from sklearn.cluster import DBSCAN\n",
    "mos = (forth_flow[0].norm(dim=1, p=1) > 0.05).detach().cpu().numpy()\n",
    "numpy_c_pc = c_pc.detach().cpu().numpy()\n",
    "numpy_forth_flow = forth_flow.detach().cpu().numpy()\n",
    "\n",
    "motion_pc = np.concatenate((numpy_c_pc[0, mos], numpy_forth_flow[0, mos]), axis=1)\n",
    "\n",
    "clustering = DBSCAN(eps=0.4, min_samples=10).fit_predict(motion_pc)\n",
    "\n",
    "\n",
    "\n",
    "visualize_points3D(motion_pc, clustering)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:28:45.790769577Z",
     "start_time": "2023-10-25T08:28:45.022691202Z"
    }
   },
   "id": "978dae8c737dee67"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "\n",
    "# 2D BEV occupancy grid\n",
    "# cell_size = 0.1\n",
    "# voxel_size = (cell_size, cell_size, cell_size)\n",
    "# voxel_size = voxel_size\n",
    "# \n",
    "# range_x, range_y, range_z = 100, 100, 10\n",
    "# size = (int(range_x / voxel_size[0]), int(range_y / voxel_size[1]), int(range_z / voxel_size[2]))\n",
    "# mid = torch.tensor([size[0] / 2, size[1] / 2, size[2] / 2], device=device, dtype=torch.long)\n",
    "# bev_grid = - torch.ones(size[:2], device=device, dtype=torch.long)\n",
    "# bev_grid.shape\n",
    "\n",
    "# flow urcuje dyn/static\n",
    "\n",
    "# visualize_multiple_pcls(*[pc2[0].cpu(), pc1[0].cpu()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-25T07:20:52.304487811Z"
    }
   },
   "id": "c8c49df7b57e44a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
